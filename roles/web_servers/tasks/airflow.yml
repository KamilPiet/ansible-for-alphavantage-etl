---

- name: Install Apache Airflow in the project's venv
  ansible.builtin.pip:
    virtualenv: "{{ web_servers_repo_path }}/venv"
    virtualenv_python: python3.12
    name: apache-airflow

- name: Initialize the Airflow database
  ansible.builtin.command:
    cmd: "{{ web_servers_repo_path }}/venv/bin/airflow db init"
  changed_when: false

- name: Add admin user for Airflow
  ansible.builtin.command:
    argv:
      - "{{ web_servers_repo_path }}/venv/bin/airflow"
      - users
      - create
      - --role
      - Admin
      - --username
      - admin
      - --password
      - "{{ web_servers_airflow_admin_password }}"
      - --email
      - "{{ web_servers_airflow_admin_email }}"
      - --firstname
      - "{{ web_servers_airflow_admin_firstname }}"
      - --lastname
      - "{{ web_servers_airflow_admin_lastname }}"
  register: add_admin_result
  changed_when: add_admin_result.stdout.find('User "admin" created with role "Admin"') != -1

- name: Check if the postgres_alphavantage connection exists
  ansible.builtin.command:
    cmd: "{{ web_servers_repo_path }}/venv/bin/airflow connections get postgres_alphavantage"
  changed_when: false
  register: connection_status
  failed_when: connection_status.rc > 1

- name: Create the postgres_alphavantage connection if necessary
  ansible.builtin.command:
    argv:
      - "{{ web_servers_repo_path }}/venv/bin/airflow"
      - connections
      - add
      - postgres_alphavantage
      - --conn-uri
      - "Postgres://{{ database_username }}:{{ database_user_password }}@192.168.0.104:5432/{{ database_name }}"
  when: connection_status.stdout == ""
  register: add_connection_result
  changed_when: add_connection_result.stdout.find('Successfully added `conn_id`=postgres_alphavantage') != -1

- name: Copy plugin files to the "airflow/plugins" directory
  ansible.builtin.copy:
    remote_src: true
    src: "{{ item.src }}"
    dest: "{{ web_servers_airflow_home }}/plugins/"
    mode: "0770"
  loop:
    - src: "{{ web_servers_repo_path }}/av_etl.py"
    - src: "{{ web_servers_repo_path }}/constants.py"
    - src: "{{ web_servers_repo_path }}/data_viz.py"
    - src: "{{ web_servers_repo_path }}/to_github_pages.py"

- name: Copy the dag file to the "airflow/dags" directory
  ansible.builtin.copy:
    remote_src: true
    src: "{{ web_servers_repo_path }}/airflow/av_etl_dag.py"
    dest: "{{ web_servers_airflow_home }}/dags/"
    mode: "0770"

- name: Create the Airflow scheduler service
  ansible.builtin.copy:
    dest: /usr/lib/systemd/system/airflow-scheduler.service
    mode: "0644"
    content: |
      #
      # Licensed to the Apache Software Foundation (ASF) under one
      # or more contributor license agreements. See the NOTICE file
      # distributed with this work for additional information
      # regarding copyright ownership. The ASF licenses this file
      # to you under the Apache License, Version 2.0 (the
      # “License”); you may not use this file except in compliance
      # with the License. You may obtain a copy of the License at
      #
      # http://www.apache.org/licenses/LICENSE-2.0
      #
      # Unless required by applicable law or agreed to in writing,
      # software distributed under the License is distributed on an
      # “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
      # KIND, either express or implied. See the License for the
      # specific language governing permissions and limitations
      # under the License.
      [Unit]
      Description=Airflow scheduler daemon
      After=network.target postgresql.service mysql.service
      Wants=postgresql.service mysql.service
      [Service]
      Environment="PATH={{ web_servers_repo_path }}/venv/bin:{{ web_servers_airflow_home }}:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      User=ansible-0
      Group=ansible
      Type=simple
      ExecStart={{ web_servers_repo_path }}/venv/bin/airflow scheduler
      Restart=always
      RestartSec=5s
      [Install]
      WantedBy=multi-user.target
  become: true

- name: Create the airflow-scheduler.service.d directory
  ansible.builtin.file:
    path: /usr/lib/systemd/system/airflow-scheduler.service.d
    state: directory
    mode: '0644'
  become: true

- name: Add a file with environment variables for the Airflow scheduler service
  ansible.builtin.copy:
    dest: /usr/lib/systemd/system/airflow-scheduler.service.d/environment.conf
    mode: "0644"
    content: |
      [Service]
      Environment="ALPHAVANTAGE_API_KEY={{ web_servers_api_key }}"
      Environment="AV_ETL_GITHUB_TOKEN={{ web_servers_github_token }}"
      Environment="AV_ETL_GIT_USERNAME={{ web_servers_git_username }}"
      Environment="AV_ETL_GIT_EMAIL={{ web_servers_git_email }}"
      Environment="AV_ETL_REMOTE_REPO={{ web_servers_git_remote_repo_url }}"
      Environment="AV_ETL_WORKING_DIR_PATH={{ web_servers_working_dir }}"
      Environment="AIRFLOW_HOME={{ web_servers_airflow_home }}"
  become: true

- name: Create the Airflow webserver service
  ansible.builtin.copy:
    dest: /usr/lib/systemd/system/airflow-webserver.service
    mode: "0644"
    content: |
      #
      # Licensed to the Apache Software Foundation (ASF) under one
      # or more contributor license agreements. See the NOTICE file
      # distributed with this work for additional information
      # regarding copyright ownership. The ASF licenses this file
      # to you under the Apache License, Version 2.0 (the
      # “License”); you may not use this file except in compliance
      # with the License. You may obtain a copy of the License at
      #
      # http://www.apache.org/licenses/LICENSE-2.0
      #
      # Unless required by applicable law or agreed to in writing,
      # software distributed under the License is distributed on an
      # “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
      # KIND, either express or implied. See the License for the
      # specific language governing permissions and limitations
      # under the License.
      [Unit]
      Description=Airflow webserver daemon
      After=network.target postgresql.service mysql.service
      Wants=postgresql.service mysql.service
      [Service]
      Environment="PATH={{ web_servers_repo_path }}/venv/bin:{{ web_servers_airflow_home }}:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      User=ansible-0
      Group=ansible
      Type=simple
      ExecStart={{ web_servers_repo_path }}/venv/bin/airflow webserver -p 8008
      Restart=on-failure
      RestartSec=5s
      PrivateTmp=true
      [Install]
      WantedBy=multi-user.target
  become: true

- name: Run daemon-reload, then enable and start the scheduler and webserver services
  ansible.builtin.systemd_service:
    daemon_reload: true
    name: "{{ item.name }}"
    enabled: true
    state: "started"
  loop:
    - name: airflow-scheduler
    - name: airflow-webserver
  become: true

- name: Wait for the alphavantage_etl_dag to be imported
  ansible.builtin.pause:
    minutes: 2

- name: Unpause the alphavantage_etl_dag
  ansible.builtin.command:
    cmd: "{{ web_servers_repo_path }}/venv/bin/airflow dags unpause alphavantage_etl_dag"
  register: unpause_dag_result
  changed_when: unpause_dag_result.stdout.find('No paused DAGs were found') == -1
